{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Phishing Brand Classification\n",
    "\n",
    "This notebook explores the website screenshot dataset for phishing brand classification.\n",
    "\n",
    "## Objectives\n",
    "1. Understand the dataset structure and class distribution\n",
    "2. Analyze image properties (dimensions, file sizes, formats)\n",
    "3. Visualize sample images from each brand\n",
    "4. Identify potential data quality issues\n",
    "5. Understand class imbalance (especially 'others' vs brands)\n",
    "\n",
    "## Key Considerations for Phishing Detection\n",
    "- The 'others' class represents benign websites - misclassifying these as brands creates false positives\n",
    "- Brand websites share visual similarities that phishing sites exploit\n",
    "- Image quality and dimensions may vary significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = project_root / 'data' / 'raw'\n",
    "FIGURES_DIR = project_root / 'outputs' / 'figures'\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "\n",
    "First, let's scan the dataset and create a comprehensive DataFrame with all image information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import scan_dataset, analyze_image_properties\n",
    "\n",
    "# Scan the dataset\n",
    "df = scan_dataset(str(DATA_DIR))\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive analysis\n",
    "analysis = analyze_image_properties(df)\n",
    "\n",
    "print(\"Dataset Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total images: {analysis['total_images']}\")\n",
    "print(f\"Number of classes: {analysis['num_classes']}\")\n",
    "print(f\"\\nFile size statistics:\")\n",
    "for key, value in analysis['file_size_stats'].items():\n",
    "    print(f\"  {key}: {value / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis\n",
    "\n",
    "Understanding class distribution is crucial for:\n",
    "- Identifying class imbalance\n",
    "- Planning data augmentation strategies\n",
    "- Setting appropriate class weights for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "class_counts = df['label'].value_counts().sort_values(ascending=True)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "colors = ['coral' if c == 'others' else 'steelblue' for c in class_counts.index]\n",
    "bars = axes[0].barh(class_counts.index, class_counts.values, color=colors)\n",
    "axes[0].set_xlabel('Number of Images')\n",
    "axes[0].set_title('Class Distribution')\n",
    "\n",
    "# Add value labels\n",
    "for bar, count in zip(bars, class_counts.values):\n",
    "    axes[0].text(bar.get_width() + max(class_counts) * 0.01, bar.get_y() + bar.get_height()/2,\n",
    "                 f'{count}', va='center', fontsize=10)\n",
    "\n",
    "# Pie chart\n",
    "# Group small classes for better visualization\n",
    "axes[1].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%',\n",
    "           colors=['coral' if c == 'others' else 'steelblue' for c in class_counts.index])\n",
    "axes[1].set_title('Class Distribution (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nClass Statistics:\")\n",
    "print(class_counts.to_frame('count'))\n",
    "print(f\"\\nImbalance ratio (max/min): {class_counts.max() / class_counts.min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze brands vs others ratio\n",
    "others_count = class_counts.get('others', 0)\n",
    "brand_count = class_counts.sum() - others_count\n",
    "\n",
    "print(f\"\\nBrands vs Others Analysis:\")\n",
    "print(f\"Total brand images: {brand_count}\")\n",
    "print(f\"Total 'others' (benign) images: {others_count}\")\n",
    "print(f\"Ratio (brands/others): {brand_count / others_count if others_count > 0 else 'N/A'}:.2f\")\n",
    "print(f\"\\nThis is important because:\")\n",
    "print(\"- 'Others' represents benign websites\")\n",
    "print(\"- False positives (benign classified as brand) = poor user experience\")\n",
    "print(\"- We need to be especially careful with 'others' classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Properties Analysis\n",
    "\n",
    "Analyze image dimensions, aspect ratios, and file formats to understand:\n",
    "- What preprocessing is needed\n",
    "- Optimal input size for the model\n",
    "- Potential quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimension analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Width distribution\n",
    "axes[0, 0].hist(df['width'].dropna(), bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Width (pixels)')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Image Width Distribution')\n",
    "axes[0, 0].axvline(df['width'].median(), color='red', linestyle='--', label=f'Median: {df[\"width\"].median():.0f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Height distribution\n",
    "axes[0, 1].hist(df['height'].dropna(), bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Height (pixels)')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Image Height Distribution')\n",
    "axes[0, 1].axvline(df['height'].median(), color='red', linestyle='--', label=f'Median: {df[\"height\"].median():.0f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Aspect ratio\n",
    "df['aspect_ratio'] = df['width'] / df['height']\n",
    "axes[1, 0].hist(df['aspect_ratio'].dropna(), bins=50, color='seagreen', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Aspect Ratio (width/height)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Aspect Ratio Distribution')\n",
    "axes[1, 0].axvline(df['aspect_ratio'].median(), color='red', linestyle='--', label=f'Median: {df[\"aspect_ratio\"].median():.2f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# File size distribution\n",
    "df['file_size_kb'] = df['file_size'] / 1024\n",
    "axes[1, 1].hist(df['file_size_kb'].dropna(), bins=50, color='purple', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('File Size (KB)')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('File Size Distribution')\n",
    "axes[1, 1].axvline(df['file_size_kb'].median(), color='red', linestyle='--', label=f'Median: {df[\"file_size_kb\"].median():.0f} KB')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'image_properties.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nImage Dimension Statistics:\")\n",
    "print(df[['width', 'height', 'aspect_ratio', 'file_size_kb']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension analysis by class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Width by class\n",
    "df.boxplot(column='width', by='label', ax=axes[0], rot=45)\n",
    "axes[0].set_title('Width Distribution by Class')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Width (pixels)')\n",
    "\n",
    "# Height by class\n",
    "df.boxplot(column='height', by='label', ax=axes[1], rot=45)\n",
    "axes[1].set_title('Height Distribution by Class')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Height (pixels)')\n",
    "\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'dimensions_by_class.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File extension distribution\n",
    "extension_counts = df['extension'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "extension_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_xlabel('File Extension')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('File Format Distribution')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "for i, v in enumerate(extension_counts.values):\n",
    "    ax.text(i, v + max(extension_counts) * 0.01, str(v), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFile formats: {extension_counts.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Visualization\n",
    "\n",
    "Visualize sample images from each class to understand:\n",
    "- Visual characteristics of each brand\n",
    "- Diversity within classes\n",
    "- Quality variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(df, class_name, n_samples=4, figsize=(16, 4)):\n",
    "    \"\"\"Display sample images from a specific class.\"\"\"\n",
    "    class_df = df[df['label'] == class_name]\n",
    "    \n",
    "    if len(class_df) == 0:\n",
    "        print(f\"No images found for class: {class_name}\")\n",
    "        return\n",
    "    \n",
    "    samples = class_df.sample(min(n_samples, len(class_df)))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_samples, figsize=figsize)\n",
    "    if n_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (ax, (_, row)) in enumerate(zip(axes, samples.iterrows())):\n",
    "        try:\n",
    "            img = Image.open(row['image_path'])\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"{row['domain'][:30]}...\\n{row['width']}x{row['height']}\")\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Error loading\\n{str(e)[:30]}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Sample Images: {class_name.upper()}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display samples from each class\n",
    "classes = df['label'].unique()\n",
    "\n",
    "for class_name in sorted(classes):\n",
    "    fig = display_sample_images(df, class_name, n_samples=4)\n",
    "    if fig:\n",
    "        plt.savefig(FIGURES_DIR / f'samples_{class_name}.png', dpi=100, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    print(f\"\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Analysis\n",
    "\n",
    "Check for potential data quality issues:\n",
    "- Corrupted images\n",
    "- Unusual dimensions\n",
    "- Very small/large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import validate_dataset\n",
    "\n",
    "# Validate all images (this may take a while for large datasets)\n",
    "print(\"Validating images...\")\n",
    "df_validated = validate_dataset(df)\n",
    "\n",
    "# Summary\n",
    "valid_count = df_validated['is_valid'].sum()\n",
    "invalid_count = (~df_validated['is_valid']).sum()\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"Valid images: {valid_count} ({valid_count/len(df)*100:.1f}%)\")\n",
    "print(f\"Invalid images: {invalid_count} ({invalid_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Show invalid images if any\n",
    "if invalid_count > 0:\n",
    "    print(f\"\\nInvalid images:\")\n",
    "    display(df_validated[~df_validated['is_valid']][['image_path', 'label', 'error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in image dimensions\n",
    "print(\"Checking for outliers...\\n\")\n",
    "\n",
    "# Small images (potential quality issues)\n",
    "small_images = df[(df['width'] < 200) | (df['height'] < 200)]\n",
    "print(f\"Very small images (<200px): {len(small_images)}\")\n",
    "\n",
    "# Large images (potential memory issues)\n",
    "large_images = df[(df['width'] > 3000) | (df['height'] > 3000)]\n",
    "print(f\"Very large images (>3000px): {len(large_images)}\")\n",
    "\n",
    "# Unusual aspect ratios\n",
    "unusual_aspect = df[(df['aspect_ratio'] < 0.5) | (df['aspect_ratio'] > 3.0)]\n",
    "print(f\"Unusual aspect ratios (<0.5 or >3.0): {len(unusual_aspect)}\")\n",
    "\n",
    "# Very small files (potential empty/corrupted)\n",
    "small_files = df[df['file_size'] < 1000]  # Less than 1KB\n",
    "print(f\"Very small files (<1KB): {len(small_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Domain Analysis\n",
    "\n",
    "Analyze the domain names in the dataset to understand:\n",
    "- URL patterns\n",
    "- Potential duplicates\n",
    "- Domain characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain analysis\n",
    "print(\"Domain Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for duplicate domains\n",
    "duplicate_domains = df[df['domain'].duplicated(keep=False)]\n",
    "print(f\"Duplicate domains: {len(duplicate_domains)}\")\n",
    "\n",
    "if len(duplicate_domains) > 0:\n",
    "    print(f\"\\nSample duplicates:\")\n",
    "    display(duplicate_domains.groupby('domain')['label'].apply(list).head(10))\n",
    "\n",
    "# Domain length statistics\n",
    "df['domain_length'] = df['domain'].str.len()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df.boxplot(column='domain_length', by='label', ax=ax, rot=45)\n",
    "ax.set_title('Domain Name Length by Class')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Domain Length (characters)')\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDomain length statistics:\")\n",
    "print(df.groupby('label')['domain_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings and Recommendations\n",
    "\n",
    "Summarize findings and provide recommendations for the modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. DATASET SIZE\")\n",
    "print(f\"   Total images: {len(df)}\")\n",
    "print(f\"   Number of classes: {df['label'].nunique()}\")\n",
    "\n",
    "print(f\"\\n2. CLASS DISTRIBUTION\")\n",
    "for cls, count in class_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    marker = \" <-- BENIGN\" if cls == 'others' else \"\"\n",
    "    print(f\"   {cls}: {count} ({pct:.1f}%){marker}\")\n",
    "\n",
    "print(f\"\\n3. IMAGE PROPERTIES\")\n",
    "print(f\"   Median dimensions: {df['width'].median():.0f} x {df['height'].median():.0f}\")\n",
    "print(f\"   Median file size: {df['file_size_kb'].median():.0f} KB\")\n",
    "print(f\"   Most common format: {df['extension'].mode().values[0]}\")\n",
    "\n",
    "print(f\"\\n4. DATA QUALITY\")\n",
    "print(f\"   Valid images: {valid_count}/{len(df)} ({valid_count/len(df)*100:.1f}%)\")\n",
    "print(f\"   Outliers identified: {len(small_images) + len(large_images) + len(unusual_aspect)}\")\n",
    "\n",
    "print(f\"\\n5. RECOMMENDATIONS\")\n",
    "print(\"   - Use image size 224x224 for EfficientNet or 384x384 for ViT\")\n",
    "print(\"   - Apply class weights to handle imbalance\")\n",
    "print(\"   - Use focal loss to focus on hard examples\")\n",
    "print(\"   - Apply data augmentation (rotation, brightness, blur)\")\n",
    "print(\"   - Set high confidence threshold to minimize false positives on 'others'\")\n",
    "print(\"   - Consider oversampling minority classes or undersampling majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataframe for next steps\n",
    "output_path = project_root / 'data' / 'processed' / 'dataset_info.csv'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Dataset info saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: Phishing Brand Classification\n",
    "\n",
    "This notebook covers data preprocessing and feature engineering for the phishing brand classifier.\n",
    "\n",
    "## Objectives\n",
    "1. Data preprocessing and cleaning\n",
    "2. Train/validation/test split with stratification\n",
    "3. Data augmentation strategies\n",
    "4. Class imbalance handling\n",
    "5. Feature visualization and analysis\n",
    "\n",
    "## Key Considerations\n",
    "- **Minimize false positives**: Benign sites ('others') should NOT be classified as brands\n",
    "- **Class imbalance**: Use weighted sampling and appropriate loss functions\n",
    "- **Data augmentation**: Simulate real-world variations in screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data.utils import scan_dataset, prepare_dataset_splits\n",
    "from src.data.transforms import get_train_transforms, get_val_transforms, AlbumentationsTransform\n",
    "from src.data.dataset import PhishingDataset\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = project_root / 'data' / 'raw'\n",
    "PROCESSED_DIR = project_root / 'data' / 'processed'\n",
    "FIGURES_DIR = project_root / 'outputs' / 'figures'\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = scan_dataset(str(DATA_DIR))\n",
    "\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class order (ensure 'others' is last for easier handling)\n",
    "CLASS_NAMES = [\n",
    "    'amazon', 'apple', 'facebook', 'google', 'instagram',\n",
    "    'linkedin', 'microsoft', 'netflix', 'paypal', 'twitter',\n",
    "    'others'\n",
    "]\n",
    "\n",
    "# Filter to only include classes in our list\n",
    "df = df[df['label'].isin(CLASS_NAMES)]\n",
    "\n",
    "print(f\"Filtered dataset size: {len(df)}\")\n",
    "print(f\"\\nClasses: {CLASS_NAMES}\")\n",
    "print(f\"Others class index: {CLASS_NAMES.index('others')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Validation/Test Split\n",
    "\n",
    "We use stratified splitting to maintain class proportions across splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split parameters\n",
    "TRAIN_SIZE = 0.70\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "# Perform stratified split\n",
    "train_df, val_df, test_df = prepare_dataset_splits(\n",
    "    df,\n",
    "    train_size=TRAIN_SIZE,\n",
    "    val_size=VAL_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify stratification\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for ax, (name, split_df) in zip(axes, [('Train', train_df), ('Validation', val_df), ('Test', test_df)]):\n",
    "    counts = split_df['label'].value_counts().sort_index()\n",
    "    colors = ['coral' if c == 'others' else 'steelblue' for c in counts.index]\n",
    "    counts.plot(kind='bar', ax=ax, color=colors)\n",
    "    ax.set_title(f'{name} Set Distribution')\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'split_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print class distribution percentages\n",
    "print(\"\\nClass distribution per split:\")\n",
    "for name, split_df in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "    dist = split_df['label'].value_counts(normalize=True) * 100\n",
    "    print(f\"\\n{name}:\")\n",
    "    for cls in CLASS_NAMES:\n",
    "        if cls in dist:\n",
    "            print(f\"  {cls}: {dist[cls]:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "train_df.to_csv(PROCESSED_DIR / 'train.csv', index=False)\n",
    "val_df.to_csv(PROCESSED_DIR / 'val.csv', index=False)\n",
    "test_df.to_csv(PROCESSED_DIR / 'test.csv', index=False)\n",
    "\n",
    "print(f\"Splits saved to {PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "\n",
    "Data augmentation is crucial for:\n",
    "- Increasing effective dataset size\n",
    "- Improving model generalization\n",
    "- Simulating real-world variations in screenshots\n",
    "\n",
    "### Augmentation Strategy\n",
    "For website screenshots, we apply:\n",
    "- **Geometric**: Slight rotation, horizontal flip (pages can be mirrored)\n",
    "- **Color**: Brightness/contrast changes, color jitter\n",
    "- **Quality**: Blur, compression artifacts, noise\n",
    "\n",
    "We avoid vertical flips as websites are not vertically symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size for model input\n",
    "IMAGE_SIZE = 224  # Standard for EfficientNet/ResNet\n",
    "\n",
    "# Get transforms\n",
    "train_transform = get_train_transforms(image_size=IMAGE_SIZE)\n",
    "val_transform = get_val_transforms(image_size=IMAGE_SIZE)\n",
    "\n",
    "print(\"Training transforms:\")\n",
    "print(train_transform)\n",
    "print(\"\\nValidation transforms:\")\n",
    "print(val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(image_path, transform, n_augments=8, figsize=(16, 8)):\n",
    "    \"\"\"Visualize multiple augmentations of an image.\"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    n_cols = 4\n",
    "    n_rows = (n_augments + 1 + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original', fontsize=10)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Augmented versions\n",
    "    for i in range(n_augments):\n",
    "        augmented = transform(image=img_array)['image']\n",
    "        # Convert from tensor if needed\n",
    "        if isinstance(augmented, torch.Tensor):\n",
    "            # Denormalize\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            augmented = augmented * std + mean\n",
    "            augmented = augmented.permute(1, 2, 0).numpy()\n",
    "            augmented = np.clip(augmented, 0, 1)\n",
    "        \n",
    "        axes[i + 1].imshow(augmented)\n",
    "        axes[i + 1].set_title(f'Augmentation {i+1}', fontsize=10)\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for j in range(n_augments + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentations for a sample image from each class\n",
    "for class_name in ['google', 'facebook', 'others']:\n",
    "    class_df = train_df[train_df['label'] == class_name]\n",
    "    if len(class_df) > 0:\n",
    "        sample = class_df.sample(1).iloc[0]\n",
    "        print(f\"\\nAugmentations for {class_name.upper()} class:\")\n",
    "        fig = visualize_augmentations(sample['image_path'], train_transform, n_augments=7)\n",
    "        plt.savefig(FIGURES_DIR / f'augmentations_{class_name}.png', dpi=100, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Imbalance Handling\n",
    "\n",
    "For phishing detection, handling class imbalance is critical:\n",
    "\n",
    "### Strategies\n",
    "1. **Class weights**: Higher weight for minority classes in loss function\n",
    "2. **Weighted sampling**: Oversample minority classes during training\n",
    "3. **Focal loss**: Focus on hard-to-classify examples\n",
    "\n",
    "### Special Handling for 'Others'\n",
    "The 'others' class needs special attention:\n",
    "- False positives (benign â†’ brand) create poor user experience\n",
    "- May need higher confidence threshold for brand classification\n",
    "- Consider asymmetric loss penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "train_dataset = PhishingDataset(\n",
    "    data_dir=str(DATA_DIR),\n",
    "    df=train_df,\n",
    "    transform=AlbumentationsTransform(train_transform),\n",
    "    class_names=CLASS_NAMES\n",
    ")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = train_dataset.get_class_weights()\n",
    "\n",
    "print(\"Class weights (inverse frequency):\")\n",
    "for name, weight in zip(CLASS_NAMES, class_weights):\n",
    "    marker = \" <-- BENIGN\" if name == 'others' else \"\"\n",
    "    print(f\"  {name}: {weight:.3f}{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class weights\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "colors = ['coral' if c == 'others' else 'steelblue' for c in CLASS_NAMES]\n",
    "bars = ax.bar(CLASS_NAMES, class_weights.numpy(), color=colors, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Class Weights for Training')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, weight in zip(bars, class_weights):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "           f'{weight:.2f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'class_weights.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate weighted sampling effect\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "\n",
    "# Get sample weights\n",
    "sample_weights = train_dataset.get_sample_weights()\n",
    "\n",
    "# Create weighted sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# Create dataloader with sampler\n",
    "loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
    "\n",
    "# Check distribution after one epoch of sampling\n",
    "sampled_labels = []\n",
    "for _, labels, _ in loader:\n",
    "    sampled_labels.extend(labels.numpy())\n",
    "\n",
    "# Compare distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original distribution\n",
    "orig_counts = train_df['label'].value_counts().sort_index()\n",
    "axes[0].bar(CLASS_NAMES, [orig_counts.get(c, 0) for c in CLASS_NAMES],\n",
    "           color=['coral' if c == 'others' else 'steelblue' for c in CLASS_NAMES])\n",
    "axes[0].set_title('Original Distribution')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Sampled distribution\n",
    "from collections import Counter\n",
    "sampled_counts = Counter(sampled_labels)\n",
    "axes[1].bar(CLASS_NAMES, [sampled_counts.get(i, 0) for i in range(len(CLASS_NAMES))],\n",
    "           color=['coral' if c == 'others' else 'steelblue' for c in CLASS_NAMES])\n",
    "axes[1].set_title('After Weighted Sampling (1 epoch)')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'weighted_sampling_effect.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nWeighted sampling helps balance class representation during training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Analysis: Pretrained Model Features\n",
    "\n",
    "Analyze feature representations from a pretrained model to understand:\n",
    "- How well brands are separated in feature space\n",
    "- Potential confusion between classes\n",
    "- Quality of pretrained features for our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load pretrained model for feature extraction\n",
    "feature_extractor = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)\n",
    "feature_extractor.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "print(f\"Feature extractor loaded on {device}\")\n",
    "print(f\"Feature dimension: {feature_extractor.num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for a subset of images\n",
    "val_dataset = PhishingDataset(\n",
    "    data_dir=str(DATA_DIR),\n",
    "    df=val_df,\n",
    "    transform=AlbumentationsTransform(val_transform),\n",
    "    class_names=CLASS_NAMES\n",
    ")\n",
    "\n",
    "# Sample subset for visualization\n",
    "n_samples = min(500, len(val_dataset))\n",
    "indices = np.random.choice(len(val_dataset), n_samples, replace=False)\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "print(f\"Extracting features from {n_samples} images...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in indices:\n",
    "        img, label, _ = val_dataset[idx]\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        feat = feature_extractor(img)\n",
    "        features.append(feat.cpu().numpy())\n",
    "        labels.append(label)\n",
    "\n",
    "features = np.vstack(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction with t-SNE\n",
    "print(\"Running t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_SEED, perplexity=30)\n",
    "features_2d = tsne.fit_transform(features)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Define colors for each class\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(CLASS_NAMES)))\n",
    "color_map = {i: colors[i] for i in range(len(CLASS_NAMES))}\n",
    "color_map[CLASS_NAMES.index('others')] = 'gray'  # Make 'others' gray\n",
    "\n",
    "for class_idx in range(len(CLASS_NAMES)):\n",
    "    mask = labels == class_idx\n",
    "    ax.scatter(\n",
    "        features_2d[mask, 0],\n",
    "        features_2d[mask, 1],\n",
    "        c=[color_map[class_idx]],\n",
    "        label=CLASS_NAMES[class_idx],\n",
    "        alpha=0.6,\n",
    "        s=50\n",
    "    )\n",
    "\n",
    "ax.set_title('t-SNE Visualization of Pretrained Features', fontsize=14)\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'tsne_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Check if brands form distinct clusters\")\n",
    "print(\"- Look for overlaps that might cause confusion\")\n",
    "print(\"- 'Others' (gray) should ideally be separate from brand clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confidence Threshold Analysis\n",
    "\n",
    "Understanding the importance of confidence thresholding for minimizing false positives.\n",
    "\n",
    "**Key Insight**: By setting a higher confidence threshold, we can reject uncertain predictions and classify them as 'others' (benign), reducing false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate threshold effects\n",
    "def simulate_threshold_effect(confidences, is_correct, thresholds):\n",
    "    \"\"\"Analyze effect of confidence thresholds on accuracy and rejection rate.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        accepted = confidences >= thresh\n",
    "        rejected = ~accepted\n",
    "        \n",
    "        # Accuracy on accepted predictions\n",
    "        if accepted.sum() > 0:\n",
    "            acc = is_correct[accepted].mean()\n",
    "        else:\n",
    "            acc = 0\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': thresh,\n",
    "            'accepted_rate': accepted.mean(),\n",
    "            'rejected_rate': rejected.mean(),\n",
    "            'accuracy_on_accepted': acc\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Generate synthetic confidence/correctness data for demonstration\n",
    "np.random.seed(RANDOM_SEED)\n",
    "n_samples = 1000\n",
    "\n",
    "# Simulate: correct predictions tend to have higher confidence\n",
    "is_correct = np.random.binomial(1, 0.85, n_samples).astype(bool)\n",
    "confidences = np.where(\n",
    "    is_correct,\n",
    "    np.random.beta(8, 2, n_samples),  # Higher confidence for correct\n",
    "    np.random.beta(2, 5, n_samples)   # Lower confidence for incorrect\n",
    ")\n",
    "\n",
    "# Analyze thresholds\n",
    "thresholds = np.arange(0.5, 0.99, 0.05)\n",
    "threshold_analysis = simulate_threshold_effect(confidences, is_correct, thresholds)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Threshold vs Accuracy\n",
    "axes[0].plot(threshold_analysis['threshold'], threshold_analysis['accuracy_on_accepted'],\n",
    "            'b-o', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Confidence Threshold')\n",
    "axes[0].set_ylabel('Accuracy on Accepted Predictions')\n",
    "axes[0].set_title('Accuracy vs Confidence Threshold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim(0.8, 1.0)\n",
    "\n",
    "# Threshold vs Rejection Rate\n",
    "axes[1].plot(threshold_analysis['threshold'], threshold_analysis['rejected_rate'],\n",
    "            'r-o', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Confidence Threshold')\n",
    "axes[1].set_ylabel('Rejection Rate')\n",
    "axes[1].set_title('Rejection Rate vs Confidence Threshold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'threshold_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThreshold Analysis:\")\n",
    "print(threshold_analysis.to_string(index=False))\n",
    "print(\"\\n** Higher threshold = Fewer false positives, but more rejections **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "### Key Preprocessing Decisions\n",
    "\n",
    "1. **Image Size**: 224x224 for EfficientNet (can try 384x384 for ViT)\n",
    "2. **Split Ratio**: 70/15/15 with stratification\n",
    "3. **Augmentation**: Rotation, brightness, blur, compression artifacts\n",
    "4. **Class Imbalance**: \n",
    "   - Weighted sampling during training\n",
    "   - Focal loss for hard examples\n",
    "   - Class weights in loss function\n",
    "5. **Confidence Threshold**: ~0.85 to minimize false positives\n",
    "\n",
    "### Files Generated\n",
    "- `data/processed/train.csv`\n",
    "- `data/processed/val.csv`\n",
    "- `data/processed/test.csv`\n",
    "- Various analysis figures in `outputs/figures/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessing configuration\n",
    "import yaml\n",
    "\n",
    "preprocess_config = {\n",
    "    'image_size': IMAGE_SIZE,\n",
    "    'class_names': CLASS_NAMES,\n",
    "    'others_class_idx': CLASS_NAMES.index('others'),\n",
    "    'split': {\n",
    "        'train': TRAIN_SIZE,\n",
    "        'val': VAL_SIZE,\n",
    "        'test': TEST_SIZE\n",
    "    },\n",
    "    'class_weights': class_weights.tolist(),\n",
    "    'recommended_confidence_threshold': 0.85,\n",
    "    'random_seed': RANDOM_SEED\n",
    "}\n",
    "\n",
    "with open(PROCESSED_DIR / 'preprocess_config.yaml', 'w') as f:\n",
    "    yaml.dump(preprocess_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Preprocessing configuration saved to {PROCESSED_DIR / 'preprocess_config.yaml'}\")\n",
    "print(\"\\nReady for model training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
